{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras_resnet import ResnetModel\n",
    "from data_helper import ImageGenerator, get_train_matrices, get_test_matrices, ValidGenerator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "img_channels = 3\n",
    "output_size = 17\n",
    "batch_size = 128\n",
    "batches = 1 * 128 // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "keras 2.0.5\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)\n",
      "system     : Darwin\n",
      "release    : 16.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 724e22391b321f57298f4333b0928e6023d4849e\n"
     ]
    }
   ],
   "source": [
    "%watermark -vmp keras -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [05:27<00:00, 123.48it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, labels_map = get_train_matrices(\"/Users/westside/dev/python/planet-amazon-deforestation/input/train_v2.csv\", \"/Users/westside/dev/python/planet-amazon-deforestation/input/train-jpg\", img_size)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n",
    "flow = ImageGenerator().get_train_generator(X_train, y_train)\n",
    "validation_generator = ValidGenerator().get_valid_generator(X_valid, y_valid)\n",
    "validation_steps = 1#len(y_valid) // 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.api.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"resnet_weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/westside/dev/python/jupyter/amazon-planet/keras_resnet.py:41: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  self.model = Model(input=self.resnet.input, output=predictions)\n"
     ]
    }
   ],
   "source": [
    "model = ResnetModel(output_size=output_size)\n",
    "pretrain = False\n",
    "\n",
    "if pretrain:\n",
    "    learn_rates = [0.001]#, 0.0001, 0.00001, 0.000001]\n",
    "    epochs_list = [1]#, 1, 1, 1]\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for lr, epochs in zip(learn_rates, epochs_list):\n",
    "        tmp_train_losses, tmp_val_losses, fbeta_score, thresholds = model.fit(flow, epochs, lr, validation_generator, y_valid, train_callbacks=[checkpoint], batches=batches)\n",
    "        print(\"fbeta = {}\".format(fbeta_score))\n",
    "        train_losses += tmp_train_losses\n",
    "        val_losses += tmp_val_losses\n",
    "        \n",
    "    learn_rates = [0.001]#, 0.0001, 0.00001, 0.000001]\n",
    "    epochs_list = [1]#, 1, 1, 1]\n",
    "\n",
    "    for lr, epochs in zip(learn_rates, epochs_list):\n",
    "        tmp_train_losses, tmp_val_losses, fbeta_score, thresholds = model.fit(flow, epochs, lr, validation_generator,y_valid, resnet_layers_trainable=15,  train_callbacks=[checkpoint], batches=batches)\n",
    "        print(\"fbeta = {}\".format(fbeta_score))\n",
    "        train_losses += tmp_train_losses\n",
    "        val_losses += tmp_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"resnet_weights.best.hdf5\")\n",
    "print(\"Weights loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8be357f096cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train\n",
    "gc.collect()\n",
    "\n",
    "x_test, x_test_filename = get_test_matrices(\"/Users/westside/dev/python/planet-amazon-deforestation/input/test-jpg\", img_size)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "del x_test\n",
    "gc.collect()\n",
    "\n",
    "x_test, x_test_filename_additional = get_test_matrices(\"/Users/westside/dev/python/planet-amazon-deforestation/input/test-jpg-additional\", img_size)\n",
    "new_predictions = model.predict(x_test)\n",
    "\n",
    "del x_test\n",
    "gc.collect()\n",
    "\n",
    "predictions = np.vstack((predictions, new_predictions))\n",
    "x_test_filename = np.hstack((x_test_filename, x_test_filename_additional))\n",
    "print(\"Predictions shape: {}\\nFiles name shape: {}\\n1st predictions entry:\\n{}\".format(predictions.shape, \n",
    "                                                                              x_test_filename.shape,\n",
    "                                                                              predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_score, thresholds = model.get_fbeta_score(validation_generator, y_valid, validation_steps)\n",
    "\n",
    "tags_pred = np.array(predictions).T\n",
    "_, axs = plt.subplots(5, 4, figsize=(15, 20))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, tag_vals in enumerate(tags_pred):\n",
    "    sns.boxplot(tag_vals, orient='v', palette='Set2', ax=axs[i]).set_title(labels_map[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = model.map_predictions(predictions, labels_map, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_list = [None] * len(predicted_labels)\n",
    "for i, tags in enumerate(predicted_labels):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_s = pd.Series(list(chain.from_iterable(predicted_labels))).value_counts()\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.barplot(x=tags_s, y=tags_s.index, orient='h');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('submission_file.csv', index=False)\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
